# Default model path for scripts (override per-invocation)
MODEL_PATH=models/tinyllama-1.1b-chat-v1.0.Q5_K_M.gguf

# Default server port
PORT=8080

# Default context length
CTX=4096

# Default GPU layers (only used if you built with CUDA)
GPU_LAYERS=35